import asyncio
import os
import base64
import requests
import json
from typing import Callable
from openhands.controller.state.state import State
from openhands.core.config import (
    AppConfig,
    SandboxConfig,
    LLMConfig,
    get_llm_config_arg,
    get_parser,
)
from openhands.core.logger import openhands_logger as logger
from openhands.core.main import create_runtime, run_controller
from openhands.events.action import Action, CmdRunAction, BrowseInteractiveAction, MessageAction
from openhands.events.observation import BrowserOutputObservation
from openhands.runtime.base import Runtime
from openhands.utils.async_utils import call_async_from_sync


def get_config(
    base_container_image: str,
    outputs_path: str,
    llm_config: LLMConfig
) -> AppConfig:
    config = AppConfig(
        run_as_openhands=False,
        max_budget_per_task=4,
        max_iterations=100,
        trajectories_path=os.path.join(outputs_path, f'traj_{base_container_image}.json'),
        sandbox=SandboxConfig(
            base_container_image=base_container_image,
            enable_auto_lint=True,
            use_host_network=False,
            # large enough timeout, since some testcases take very long to run
            timeout=300,
            api_key=os.environ.get('ALLHANDS_API_KEY', None),
        ),
        # we mount trajectories path so that trajectories, generated by OpenHands
        # controller, can be accessible to the evaluator file in the runtime container
        workspace_mount_path=outputs_path,
        workspace_mount_path_in_sandbox='/outputs',
    )
    config.set_llm_config(llm_config)
    return config


def get_nextcloud_password():
    """
    Retrieves NEXTCLOUD_PASSWORD from the API endpoint

    TODO: this is a temporary solution. Once #169 is solved,
    we should be able to use a hard-coded password to avoid
    this extra API call.
    
    Returns:
        str: The NEXTCLOUD_PASSWORD value
    
    Raises:
        requests.RequestException: If API call fails
        KeyError: If NEXTCLOUD_PASSWORD is not in response
        json.JSONDecodeError: If response is not valid JSON
    """
    url = "http://the-agent-company.com:2999/api/nextcloud-config"
    
    try:
        response = requests.get(url)
        response.raise_for_status()  # Raises an exception for bad status codes
        
        data = response.json()
        return data["NEXTCLOUD_PASSWORD"]
        
    except requests.RequestException as e:
        print(f"Error making API request: {e}")
        raise
    except (KeyError, json.JSONDecodeError) as e:
        print(f"Error processing response: {e}")
        raise



def pre_login(runtime: Runtime, save_screenshots=True, screenshots_dir='screenshots'):
    """
    Logs in to all the websites that are needed for the evaluation.
    Once logged in, the sessions would be cached in the browser, so OpenHands
    agent doesn't need to log in to these websites again.

    TODO: right now we assume all login actions succeed. We need to add some sanity
    checks to ensure that login is successful.

    TODO: we only need login actions for dependencies of the task.
    """
    nextcloud_password = get_nextcloud_password()

    nextcloud_login_actions = [
        'goto("https://ogma.lti.cs.cmu.edu")',
        'fill("121", "admin")',
        f'fill("126", "{nextcloud_password}")',
        'click("134")'
    ]

    rocketchat_login_actions = [
        'goto("http://the-agent-company.com:3000/")',
        'fill("52", "theagentcompany")',
        'fill("57", "theagentcompany")',
        'click("60")',
        # after login, a popup asking to change hostname appears. We need to click on cancel button.
        # TODO: this sometimes fails, seems bid is not deterministic
        'click("219")',
    ]

    gitlab_login_actions = [
        'goto("http://the-agent-company.com:8929/users/sign_in")',
        'fill("78", "root")',
        'fill("84", "theagentcompany")',
        'click("98")',
    ]

    # TODO: this sometimes fails, seems bid for plane login is not deterministic
    # TODO (yufansong): plane reset is not stable, and sometimes it fails to launch
    plane_login_actions = [
        'goto("http://the-agent-company.com:8091")',
        'noop(5000)', 
        'fill("65", "agent@company.com")',
        'click("66")',
        'fill("85", "theagentcompany")',
        'click("92")'
    ]

    all_login_actions = [
        ('nextcloud', nextcloud_login_actions),
        ('rocket_chat', rocketchat_login_actions),
        ('gitlab', gitlab_login_actions),
        ('plane', plane_login_actions),
    ]

    for (website_name, login_actions) in all_login_actions:
        if save_screenshots:
            directory = os.path.join(screenshots_dir, website_name)
            if not os.path.exists(directory):
                os.makedirs(directory)
            image_id = 0
        for instruction in login_actions:
            action = BrowseInteractiveAction(
                browser_actions=instruction
            )
            action.timeout = 10000
            logger.info(action, extra={'msg_type': 'ACTION'})
            obs: BrowserOutputObservation = runtime.run_action(action)
            logger.info(obs, extra={'msg_type': 'OBSERVATION'})
            if save_screenshots:
                image_data = base64.b64decode(obs.screenshot)
                with open(os.path.join(directory, f'{image_id}.png'), 'wb') as file:
                    file.write(image_data)
                    image_id += 1


def init_task_env(runtime: Runtime, hostname: str, llm_config: LLMConfig):
    command = (
        f"SERVER_HOSTNAME={hostname} "
        f"LITELLM_API_KEY={llm_config.api_key} "
        f"LITELLM_BASE_URL={llm_config.base_url} "
        f"LITELLM_MODEL={llm_config.model} "
        "bash /utils/init.sh"
    )
    action = CmdRunAction(command=command)
    logger.info(action, extra={'msg_type': 'ACTION'})
    obs = runtime.run_action(action)
    logger.info(obs, extra={'msg_type': 'OBSERVATION'})
    assert obs.exit_code == 0

    # TODO (boxuanli): remove this once reset is called by init.sh
    command = (
        "bash /utils/reset.sh"
    )
    action = CmdRunAction(command=command)
    action.timeout = 1000
    logger.info(action, extra={'msg_type': 'ACTION'})
    obs = runtime.run_action(action)
    logger.info(obs, extra={'msg_type': 'OBSERVATION'})
    assert obs.exit_code == 0


def codeact_user_response(state: State) -> str:
    msg = (
        'Please continue working on the task on whatever approach you think is suitable.\n'
        'If you think you have solved the task, please finish the interaction.\n'
        'IMPORTANT: YOU SHOULD NEVER ASK FOR HUMAN HELP.\n'
    )

    if state.history:
        # check if the agent has tried to talk to the user 3 times, if so, let the agent know it can give up
        user_msgs = [
            event
            for event in state.history
            if isinstance(event, MessageAction) and event.source == 'user'
        ]
        if len(user_msgs) >= 2:
            # let the agent know that it can give up when it has tried 3 times
            return (
                msg
                + 'If you want to give up, run: <execute_bash> exit </execute_bash>.\n'
            )
    return msg


def run_solver(runtime: Runtime, task_name: str, config: AppConfig) -> State:
    instruction = "Complete the task in /instruction/task.md"

    # TODO: OpenHands should optionally, save browser screenshots to a place
    state: State | None = asyncio.run(
        run_controller(
            config=config,
            sid=task_name,
            initial_user_action=MessageAction(content=instruction),
            runtime=runtime,
            fake_user_response_fn=codeact_user_response,
        )
    )
    logger.info(state)
    return state


def run_evaluator(runtime: Runtime, llm_config: LLMConfig, trajectory_path: str, result_path: str):
    command = (
        f"LITELLM_API_KEY={llm_config.api_key} "
        f"LITELLM_BASE_URL={llm_config.base_url} "
        f"LITELLM_MODEL={llm_config.model} "
        f"python_default /utils/eval.py --trajectory_path {trajectory_path} --result_path {result_path}"
    )
    action = CmdRunAction(command=command)
    action.timeout = 600
    logger.info(action, extra={'msg_type': 'ACTION'})
    obs = runtime.run_action(action)
    logger.info(obs, extra={'msg_type': 'OBSERVATION'})
    assert obs.exit_code == 0


if __name__ == '__main__':
    parser = get_parser()
    parser.add_argument(
        '--task-image-name',
        type=str,
        default='example-exam-image',
        help='Task image name',
    )
    parser.add_argument(
        '--outputs-path',
        type=str,
        default='./outputs',
        help='Folder path to save trajectories and evaluation results'
    )
    parser.add_argument(
        '--server-hostname',
        type=str,
        default='ogma.lti.cs.cmu.edu',
        help='Server hostname, e.g. ogma.lti.cs.cmu.edu'
    )
    args, _ = parser.parse_known_args()

    llm_config: LLMConfig | None = None
    if args.llm_config:
        llm_config = get_llm_config_arg(args.llm_config)

    if llm_config is None:
        raise ValueError(f'Could not find LLM config: --llm_config {args.llm_config}')

    logger.info(f"Task image name is {args.task_image_name}")
    config: AppConfig = get_config(args.task_image_name, os.path.abspath(args.outputs_path), llm_config)
    runtime: Runtime = create_runtime(config)
    call_async_from_sync(runtime.connect)

    init_task_env(runtime, args.server_hostname, llm_config)

    pre_login(runtime)

    state = run_solver(runtime, args.task_image_name, config)

    # this path is the absolute path in the runtime container
    trajectory_path = f'/outputs/traj_{args.task_image_name}.json'
    result_path = f'/outputs/eval_{args.task_image_name}.json'

    run_evaluator(runtime, llm_config, trajectory_path, result_path)
